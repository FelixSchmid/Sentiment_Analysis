{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1_Sentiment_Analysis_IMBD_TFIDF.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FelixSchmid/Sentiment_Analysis/blob/master/1_Sentiment_Analysis_IMBD_TFIDF.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8DrR5AHfgwmZ"
      },
      "source": [
        "# Sentiment classification - close to the state of the art\n",
        "\n",
        "The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured.\n",
        "\n",
        "For this assignment you have to use the larger [IMDB sentiment](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) benchmark dataset from Stanford, an achieve close to state of the art results.\n",
        "\n",
        "The task is to try out multiple models in ascending complexity, namely:\n",
        "\n",
        "1. TFIDF + classical statistical model (eg. RandomForest)\n",
        "2. LSTM classification model\n",
        "3. LSTM model, where the embeddings are initialized with pre-trained GloVe vectors\n",
        "4. fastText model\n",
        "5. BERT based model (you are advised to use a pre-trained one and finetune, since the resource consumption is considerable!)\n",
        "\n",
        "You should get over 90% validation accuracy (though nearly 94 is achievable).\n",
        "\n",
        "You are allowed to use any library or tool, though the Keras environment, and some wrappers on top (ie. Ktrain) make your life easier.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wsgmKyD6gwmd"
      },
      "source": [
        "__Groups__\n",
        "This assignment is to be completed individually, two weeks after the class has finished. For the precise deadline please see canvas.\n",
        "\n",
        "__Format of submission__\n",
        "You need to submit a pdf of your Google Collab notebooks.\n",
        "\n",
        "__Due date__\n",
        "Two weeks after the class has finished. For the precise deadline please see canvas.\n",
        "\n",
        "Grade distribution:\n",
        "1. TFIDF + classical statistical model (eg. RandomForest) (25% of the final grade)\n",
        "2. LSTM classification model (15% of the final grade)\n",
        "3. LSTM model, where the embeddings are initialized with pre-trained GloVe vectors (15% of the final grade)\n",
        "4. fastText model (15% of the final grade)\n",
        "5. BERT based model (you are advised to use a pre-trained one and finetune it, since the resource consumption is considerable!) (30% of the final grade). For BERT you should get over 90% validation accuracy (though nearly 94% is achievable).\n",
        "\n",
        "\n",
        "__For each of the models, the marks will be awarded according to the following three criteria__:\n",
        "\n",
        "(1) The (appropriately measured) accuracy of your prediction for the task. The more accurate the prediction is, the better. Note that you need to validate the predictive accuracy of your model on a hold-out of unseen data that the model has not been trained with.\n",
        "\n",
        "(2) How well you motivate the use of the model - what in this model's structure makes it suited for representing sentiment? After using the model for the task how well you evaluate the accuracy you got for each model and discuss the main advantages and disadvantages the model has in the particular modelling task. At best you take part of the modelling to support your arguments.\n",
        "\n",
        "(3) The consistency of your take-aways, i.e. what you have learned from your analyses. Also, analyze when the model is good and when and where it does not predict well.\n",
        "\n",
        "Please make sure that you comment with # on the separates steps of the code you have produced. For the verbal description and analyses plesae insert markdown cells.\n",
        "\n",
        "\n",
        "__Plagiarism__: The Frankfurt School does not accept any plagiarism. Data science is a collaborative exercise and you can discuss the research question with your classmates from other groups, if you like. You must not copy any code or text though. Plagiarism will be prosecuted and will result in a mark of 0 and you failing this class.\n",
        "\n",
        "After carefully reading this document and having had a look at the data you may still have questions. Please submit those question to the public Q&A board in canvas and we will answer each question, so "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "LE48lNm26XwJ"
      },
      "source": [
        "# Importing data and libraries (notebook 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gEwjTzd8rqjR",
        "colab": {}
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o2vbs9ZQZr_A",
        "colab": {}
      },
      "source": [
        "# I later on safe preprcessed data and trained models on my google drive.\n",
        "# With this two lines of code I can mount the drive with colab.\n",
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_eAgGDG2xQmm",
        "colab": {}
      },
      "source": [
        "import os,re,string\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_files\n",
        "import gensim, spacy, logging, warnings\n",
        "from gensim import corpora, models\n",
        "from gensim.models.phrases import Phrases, Phraser\n",
        "import numpy as np\n",
        "from gensim.matutils import sparse2full\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn import linear_model\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.externals import joblib\n",
        "import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NGIRjQ-YMQAQ",
        "colab": {}
      },
      "source": [
        "%%capture\n",
        "!pip install spacy gensim pprint\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install wordcloud bokeh"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "k3JYcaUVJk-M"
      },
      "source": [
        "# 1. TFIDF + classical statistical model\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gwc3QLELIrjC"
      },
      "source": [
        "## 1.0 Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QVTK1-9kIwV8"
      },
      "source": [
        "To use machine learning for text data, we somehow need to convert the text to numbers. There are several approaches such as Bag of Words (BoW), word2vec or ELMo. In this part of the notebook we want to use term frequencyâ€“inverse document frequency (TF-IDF).\n",
        "\n",
        "TF-IDF builts up on BoW. In the BoW approach a document is represented as a set ('bag') of its words disregarding grammer and word order. The BoW for a certain document would be a vector with the lenght of the vocabulary (unique words) of the corpus. And the vector would just contain the frequency of each word in the document. The values of the vector could be used as features for our statistical model.\n",
        "\n",
        "Every word in the document is equally important in the BoW approach. However, we might want to give words like \"the\" or \"movie\" lesser values because these are very common words in the IMBd corpus and do not really distinguish documents from each other as they are most likely distributed equally among reviews with positive and negative sentiment.\n",
        "\n",
        "The idea of TF-IDF is to give more weight to words that occur more in a certain document but less overall. Let us imagine a document that contains the word \"film\" as much as \"boring\". We want to weight \"boring\" more because in the general corpus the word \"boring\" is less frequent (for sake of the explanation, let us assume it is less frequent; I did not check.). Therefore, \"boring\" contains probably more valuable information to classify that one document. This is realized with the following formula:\n",
        "\n",
        "<img src=\"https://cdn-images-1.medium.com/max/1600/1*jNnpbGPxkjehlvTCXq9B8g.png\" width=45%>\n",
        "\n",
        "In the following code we will create a TF-IDF matrix. The rows of that matrix represent one document (review) and the columns the TF-IDF score of each word. \n",
        "\n",
        "In terms of machine learning, one row contains the features of the document with which the model will be trained. As there a many words in the corpus and only a few in each document the feature vector will be sparse. That is why we do some further preprocessing such as filtering for POS and throwing out STOP-words in advance of creating the TF-IDF matrix.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "QhBBpllpIxPY"
      },
      "source": [
        "## 1.1 Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6c0KTSmHN5Bc",
        "colab": {}
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UM9f8r8Y2bTf",
        "colab": {}
      },
      "source": [
        "# We load the data with this scikit learn function\n",
        "train_set = load_files(os.path.join('aclImdb',  'train'), shuffle=False, categories=['neg', 'pos'])\n",
        "test_set = load_files(os.path.join('aclImdb',  'test'), shuffle=False, categories=['neg', 'pos'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ETM-WzjiSfpm"
      },
      "source": [
        "**Filtering tokens that only consist of alphabetic characters:** \n",
        "\n",
        "1.   List item\n",
        "2.   List item\n",
        "\n",
        "\n",
        "Sometimes reviewers end their text with quantitative ratings such as \"8/10\". While this might be an useful information for the task of sentiment analysis for movies. I decided to throw it out because it might not be generalizable and we want a model that 'decides' based on qualitative text only."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "J0-IwGxrOAUO",
        "outputId": "fea0a999-c0ef-4e89-dc3a-a500aa1ff92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "def text_to_words(text):\n",
        "    # tokanization of text\n",
        "    doc = nlp(text)\n",
        "    token_list = []\n",
        "    for token in doc:\n",
        "      lower = token.lower_\n",
        "      if token.is_alpha == True and len(lower) >= 2 and len(lower) <=15:\n",
        "        token_list.append(lower)\n",
        "    \n",
        "    return token_list\n",
        "\n",
        "# text values from train set\n",
        "train_texts = train_set.data\n",
        "train_texts_words = [text_to_words(text.decode('utf8')) for text in train_texts]\n",
        "\n",
        "test_texts = test_set.data\n",
        "test_texts_words = [text_to_words(text.decode('utf8')) for text in test_texts]\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7min 23s, sys: 2.9 s, total: 7min 26s\n",
            "Wall time: 7min 26s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5q8gRf_hgqKr",
        "outputId": "29d73e9c-4a5f-4c34-cbd1-315e7fb98565",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_texts_words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['story', 'of', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'pig', 'starts', 'out', 'with', 'opening', 'scene', 'that', 'is', 'terrific', 'example', 'of', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'is', 'turned', 'into', 'an', 'insane', 'violent', 'mob', 'by', 'the', 'crazy', 'chantings', 'of', 'it', 'singers', 'unfortunately', 'it', 'stays', 'absurd', 'the', 'whole', 'time', 'with', 'no', 'general', 'narrative', 'eventually', 'making', 'it', 'just', 'too', 'off', 'putting', 'even', 'those', 'from', 'the', 'era', 'should', 'be', 'turned', 'off', 'the', 'cryptic', 'dialogue', 'would', 'make', 'shakespeare', 'seem', 'easy', 'to', 'third', 'grader', 'on', 'technical', 'level', 'it', 'better', 'than', 'you', 'might', 'think', 'with', 'some', 'good', 'cinematography', 'by', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'stars', 'sally', 'kirkland', 'and', 'frederic', 'forrest', 'can', 'be', 'seen', 'briefly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "MfZxePU9Sjbz"
      },
      "source": [
        "**Creating bi- and trigrams**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MD2yNNIFOLx9",
        "outputId": "f8790a42-93ae-467a-a240-71e68f2f90b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 110
        }
      },
      "source": [
        "%%time\n",
        "def create_trigram_phraser(texts_words):\n",
        "\n",
        "    bigram_phrases = Phrases(texts_words, threshold=100)\n",
        "    trigram_phrases = Phrases(bigram_phrases[texts_words], threshold=100) \n",
        "\n",
        "    # Technical pruning\n",
        "    bigram_phraser = gensim.models.phrases.Phraser(bigram_phrases)\n",
        "    trigram_phraser = gensim.models.phrases.Phraser(trigram_phrases)\n",
        "    return trigram_phraser, bigram_phraser\n",
        "\n",
        "trigram_phraser, bigram_phraser = create_trigram_phraser(train_texts_words)\n",
        "train_texts_words = [trigram_phraser[bigram_phraser[words]] for words in train_texts_words]\n",
        "test_texts_words = [trigram_phraser[bigram_phraser[words]] for words in test_texts_words]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 43s, sys: 129 ms, total: 1min 44s\n",
            "Wall time: 1min 44s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Z56kpHz_f4bt",
        "outputId": "11c8d1ae-87df-4147-cda4-e331352a7e56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_texts_words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['story', 'of', 'man', 'who', 'has', 'unnatural', 'feelings', 'for', 'pig', 'starts', 'out', 'with', 'opening', 'scene', 'that', 'is', 'terrific', 'example', 'of', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'is', 'turned', 'into', 'an', 'insane', 'violent', 'mob', 'by', 'the', 'crazy', 'chantings', 'of', 'it', 'singers', 'unfortunately', 'it', 'stays', 'absurd', 'the', 'whole', 'time', 'with', 'no', 'general', 'narrative', 'eventually', 'making', 'it', 'just', 'too', 'off', 'putting', 'even', 'those', 'from', 'the', 'era', 'should', 'be', 'turned', 'off', 'the', 'cryptic', 'dialogue', 'would', 'make', 'shakespeare', 'seem', 'easy', 'to', 'third', 'grader', 'on', 'technical', 'level', 'it', 'better', 'than', 'you', 'might', 'think', 'with', 'some', 'good', 'cinematography', 'by', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'stars', 'sally_kirkland', 'and', 'frederic', 'forrest', 'can', 'be', 'seen', 'briefly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "0IAOXkh2S9Zz"
      },
      "source": [
        "**Filtering non-stopwords and ['NOUN', 'ADJ', 'VERB', 'ADV', 'INTJ']:**\n",
        "Nouns, adjectives, verbs, adverbs and interjections should contain the most useful information. Therefore, we keep all tokens with these POS. In the first run I did not keep interjections ('ahh', 'hmmm') and got slightly worse results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nm5XxNbUQ2pK",
        "outputId": "72f7d7a4-8d9a-4fae-a4e8-94c40a7c4f0e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "def filter_words_to_lemmas(texts_words):\n",
        "    filtered_texts_lemmas = []\n",
        "\n",
        "    for words in texts_words:\n",
        "       doc = spacy.tokens.Doc(nlp.vocab, words=words)\n",
        "       tagged = nlp.get_pipe(\"tagger\")(doc)\n",
        "       lemmas = [word.lemma_ for word in tagged \\\n",
        "                  if word.pos_ in ['NOUN', 'ADJ', 'VERB', 'ADV', 'INTJ']\n",
        "                  and word.is_stop == False] \n",
        "       filtered_texts_lemmas.append(lemmas)\n",
        "\n",
        "    return filtered_texts_lemmas\n",
        "\n",
        "train_texts_words = filter_words_to_lemmas(train_texts_words)\n",
        "test_texts_words = filter_words_to_lemmas(test_texts_words)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 5min 49s, sys: 1.51 s, total: 5min 50s\n",
            "Wall time: 5min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "VkwCyqVyl2BZ",
        "outputId": "ab6bd9a1-4b57-4295-f800-90e3f1d1ba19",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "print(train_texts_words[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['story', 'man', 'unnatural', 'feeling', 'pig', 'start', 'open', 'scene', 'terrific', 'example', 'absurd', 'comedy', 'formal', 'orchestra', 'audience', 'turn', 'insane', 'violent', 'mob', 'crazy', 'chanting', 'singer', 'unfortunately', 'stay', 'absurd', 'time', 'general', 'narrative', 'eventually', 'make', 'put', 'era', 'turn', 'cryptic', 'dialogue', 'shakespeare', 'easy', 'grader', 'technical', 'level', 'better', 'think', 'good', 'cinematography', 'future', 'great', 'vilmos', 'zsigmond', 'future', 'star', 'sally_kirkland', 'frederic', 'forrest', 'see', 'briefly']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "pgd2xBvTTA7a"
      },
      "source": [
        "**Creating a TF-IDF matrix** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "el_nTMTDOVFM",
        "colab": {}
      },
      "source": [
        "# Creating id2word and TfidfModel based on train only to not leak information.\n",
        "# Then applying to test set...\n",
        "\n",
        "# Create Dictionary on train data\n",
        "id2word = gensim.corpora.Dictionary(train_texts_words)\n",
        "id2word.filter_extremes(keep_n=5000)\n",
        "\n",
        "# Term Document Frequency\n",
        "train_corpus = [id2word.doc2bow(words) for words in train_texts_words]\n",
        "\n",
        "# Applying Term Document Frequency on test set\n",
        "test_corpus = [id2word.doc2bow(words) for words in test_texts_words]\n",
        "\n",
        "# Fit Tfidf on train\n",
        "tfidf = gensim.models.TfidfModel(train_corpus) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kTPyXDEftI3Y",
        "outputId": "bc1ef815-8459-4758-e71e-5e8092462d1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "for doc in train_corpus[:2]:\n",
        "    print([[id2word[id], freq] for id, freq in doc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['absurd', 2], ['audience', 1], ['better', 1], ['briefly', 1], ['cinematography', 1], ['comedy', 1], ['crazy', 1], ['dialogue', 1], ['easy', 1], ['era', 1], ['eventually', 1], ['example', 1], ['feeling', 1], ['future', 2], ['general', 1], ['good', 1], ['great', 1], ['insane', 1], ['level', 1], ['make', 1], ['man', 1], ['mob', 1], ['narrative', 1], ['open', 1], ['pig', 1], ['put', 1], ['scene', 1], ['see', 1], ['shakespeare', 1], ['singer', 1], ['star', 1], ['start', 1], ['stay', 1], ['story', 1], ['technical', 1], ['terrific', 1], ['think', 1], ['time', 1], ['turn', 2], ['unfortunately', 1], ['violent', 1]]\n",
            "[['dialogue', 1], ['good', 2], ['great', 3], ['make', 1], ['open', 2], ['scene', 4], ['see', 1], ['star', 1], ['start', 1], ['stay', 1], ['think', 2], ['time', 4], ['unfortunately', 1], ['acting', 1], ['action', 1], ['actually', 1], ['add', 1], ['adventure', 1], ['air', 4], ['airport', 11], ['alright', 1], ['await', 1], ['bad', 2], ['badly', 1], ['bang', 1], ['barely', 1], ['belong', 1], ['bite', 1], ['bland', 1], ['board', 1], ['body', 1], ['boring', 1], ['bunch', 1], ['businessman', 1], ['character', 2], ['choice', 1], ['christopher_lee', 1], ['classic', 1], ['co', 1], ['control', 1], ['couple', 2], ['course', 1], ['crash', 1], ['crew', 1], ['cross', 1], ['cut', 1], ['danger', 1], ['date', 1], ['daughter', 1], ['dead', 1], ['decent', 1], ['descent', 1], ['design', 1], ['different', 1], ['dilemma', 1], ['direct', 1], ['direction', 1], ['disaster', 4], ['discovery', 1], ['door', 1], ['drown', 1], ['drunk', 1], ['dull', 2], ['effect', 1], ['end', 1], ['entertain', 2], ['estate', 1], ['excitement', 1], ['expect', 1], ['extra', 2], ['face', 1], ['far', 2], ['fashion', 1], ['fast', 1], ['favourite', 1], ['flashback', 1], ['flesh', 1], ['flick', 2], ['flood', 1], ['fly', 3], ['follow', 1], ['footage', 2], ['forget', 1], ['gas', 1], ['generate', 1], ['get', 1], ['give', 1], ['grant', 1], ['hall', 1], ['happen', 1], ['harsh', 1], ['have', 1], ['helicopter', 1], ['help', 2], ['hi', 2], ['hit', 1], ['home', 1], ['horrible', 1], ['hour', 2], ['huge', 1], ['idea', 2], ['include', 2], ['inside', 1], ['interior', 1], ['involved', 1], ['island', 1], ['isolated', 1], ['jack', 2], ['james_stewart', 2], ['jerry', 1], ['joe', 1], ['julie', 1], ['keep', 1], ['knock', 1], ['know', 1], ['lack', 2], ['land', 1], ['lee', 1], ['like', 3], ['little', 4], ['load', 1], ['long', 1], ['look', 4], ['lose', 1], ['lot', 1], ['maker', 1], ['maybe', 1], ['mean', 1], ['michael', 1], ['mid', 2], ['middle', 1], ['mile', 1], ['minute', 2], ['miss', 1], ['mistake', 1], ['model', 1], ['mount', 1], ['museum', 1], ['navy', 1], ['necessarily', 1], ['new', 1], ['nice', 1], ['ocean', 1], ['odd', 1], ['oil', 2], ['old', 1], ['opening_credit', 1], ['opportunity', 1], ['original', 1], ['pace', 1], ['painting', 1], ['passenger', 1], ['period', 1], ['philip', 1], ['pick', 1], ['pilot', 1], ['place', 1], ['plan', 2], ['plane', 7], ['plenty', 1], ['plot', 2], ['popular', 1], ['predecessor', 1], ['prefer', 1], ['pretty', 1], ['pride', 1], ['problem', 1], ['production', 1], ['production_value', 1], ['public', 1], ['real', 1], ['reason', 1], ['rescue', 1], ['rich', 1], ['right', 2], ['run', 3], ['say', 2], ['sea', 1], ['second', 1], ['send', 1], ['sequel', 2], ['sequence', 1], ['shame', 2], ['ship', 1], ['short', 1], ['shot', 1], ['silly', 1], ['sink', 2], ['sir', 1], ['sit_through', 1], ['sleep', 1], ['slightly', 1], ['slow', 1], ['son', 1], ['sort', 1], ['spectacular', 1], ['stark', 1], ['steal', 1], ['steven', 2], ['strip', 1], ['supply', 1], ['sure', 1], ['survivor', 1], ['suspense', 1], ['take', 2], ['tension', 2], ['theatrical', 1], ['thing', 1], ['thriller', 1], ['toy', 1], ['trap', 1], ['try', 1], ['tv', 1], ['unsympathetic', 1], ['valuable', 2], ['version', 2], ['video', 1], ['water', 1], ['wilson', 1], ['worker', 1], ['worried', 1]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SdkYIcNNCVDl",
        "outputId": "f5ce7dbb-d85d-42d7-a05e-5102b1ed7a69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "for doc in tfidf[train_corpus][:2]:\n",
        "    print([[id2word[id], np.around(freq, decimals=2)] for id, freq in doc])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['absurd', 0.38], ['audience', 0.1], ['better', 0.11], ['briefly', 0.22], ['cinematography', 0.14], ['comedy', 0.1], ['crazy', 0.15], ['dialogue', 0.12], ['easy', 0.14], ['era', 0.16], ['eventually', 0.15], ['example', 0.12], ['feeling', 0.13], ['future', 0.29], ['general', 0.15], ['good', 0.03], ['great', 0.05], ['insane', 0.2], ['level', 0.13], ['make', 0.06], ['man', 0.07], ['mob', 0.22], ['narrative', 0.18], ['open', 0.13], ['pig', 0.24], ['put', 0.15], ['scene', 0.06], ['see', 0.04], ['shakespeare', 0.21], ['singer', 0.19], ['star', 0.09], ['start', 0.08], ['stay', 0.13], ['story', 0.05], ['technical', 0.19], ['terrific', 0.17], ['think', 0.05], ['time', 0.04], ['turn', 0.17], ['unfortunately', 0.13], ['violent', 0.17]]\n",
            "[['dialogue', 0.03], ['good', 0.01], ['great', 0.04], ['make', 0.01], ['open', 0.06], ['scene', 0.05], ['see', 0.01], ['star', 0.02], ['start', 0.02], ['stay', 0.03], ['think', 0.02], ['time', 0.03], ['unfortunately', 0.03], ['acting', 0.02], ['action', 0.02], ['actually', 0.02], ['add', 0.03], ['adventure', 0.04], ['air', 0.14], ['airport', 0.63], ['alright', 0.05], ['await', 0.05], ['bad', 0.02], ['badly', 0.04], ['bang', 0.05], ['barely', 0.04], ['belong', 0.04], ['bite', 0.04], ['bland', 0.04], ['board', 0.04], ['body', 0.03], ['boring', 0.03], ['bunch', 0.03], ['businessman', 0.05], ['character', 0.02], ['choice', 0.04], ['christopher_lee', 0.06], ['classic', 0.03], ['co', 0.04], ['control', 0.04], ['couple', 0.05], ['course', 0.02], ['crash', 0.04], ['crew', 0.04], ['cross', 0.04], ['cut', 0.03], ['danger', 0.05], ['date', 0.03], ['daughter', 0.03], ['dead', 0.03], ['decent', 0.03], ['descent', 0.06], ['design', 0.04], ['different', 0.02], ['dilemma', 0.06], ['direct', 0.03], ['direction', 0.03], ['disaster', 0.17], ['discovery', 0.05], ['door', 0.04], ['drown', 0.05], ['drunk', 0.04], ['dull', 0.07], ['effect', 0.03], ['end', 0.01], ['entertain', 0.06], ['estate', 0.05], ['excitement', 0.05], ['expect', 0.02], ['extra', 0.08], ['face', 0.02], ['far', 0.04], ['fashion', 0.04], ['fast', 0.04], ['favourite', 0.04], ['flashback', 0.04], ['flesh', 0.05], ['flick', 0.06], ['flood', 0.06], ['fly', 0.11], ['follow', 0.03], ['footage', 0.08], ['forget', 0.03], ['gas', 0.05], ['generate', 0.05], ['get', 0.01], ['give', 0.02], ['grant', 0.04], ['hall', 0.05], ['happen', 0.02], ['harsh', 0.05], ['have', 0.02], ['helicopter', 0.05], ['help', 0.05], ['hi', 0.12], ['hit', 0.03], ['home', 0.03], ['horrible', 0.03], ['hour', 0.05], ['huge', 0.03], ['idea', 0.05], ['include', 0.05], ['inside', 0.05], ['interior', 0.06], ['involved', 0.05], ['island', 0.04], ['isolated', 0.06], ['jack', 0.08], ['james_stewart', 0.12], ['jerry', 0.05], ['joe', 0.04], ['julie', 0.06], ['keep', 0.03], ['knock', 0.04], ['know', 0.01], ['lack', 0.05], ['land', 0.04], ['lee', 0.04], ['like', 0.05], ['little', 0.06], ['load', 0.04], ['long', 0.02], ['look', 0.05], ['lose', 0.02], ['lot', 0.02], ['maker', 0.04], ['maybe', 0.02], ['mean', 0.02], ['michael', 0.04], ['mid', 0.09], ['middle', 0.03], ['mile', 0.04], ['minute', 0.04], ['miss', 0.03], ['mistake', 0.04], ['model', 0.04], ['mount', 0.06], ['museum', 0.06], ['navy', 0.05], ['necessarily', 0.05], ['new', 0.02], ['nice', 0.03], ['ocean', 0.05], ['odd', 0.04], ['oil', 0.1], ['old', 0.02], ['opening_credit', 0.05], ['opportunity', 0.04], ['original', 0.02], ['pace', 0.04], ['painting', 0.05], ['passenger', 0.06], ['period', 0.03], ['philip', 0.06], ['pick', 0.03], ['pilot', 0.04], ['place', 0.02], ['plan', 0.07], ['plane', 0.31], ['plenty', 0.04], ['plot', 0.03], ['popular', 0.04], ['predecessor', 0.05], ['prefer', 0.04], ['pretty', 0.02], ['pride', 0.05], ['problem', 0.03], ['production', 0.03], ['production_value', 0.04], ['public', 0.04], ['real', 0.02], ['reason', 0.02], ['rescue', 0.04], ['rich', 0.04], ['right', 0.04], ['run', 0.07], ['say', 0.04], ['sea', 0.05], ['second', 0.02], ['send', 0.03], ['sequel', 0.07], ['sequence', 0.03], ['shame', 0.07], ['ship', 0.04], ['short', 0.03], ['shot', 0.03], ['silly', 0.03], ['sink', 0.09], ['sir', 0.05], ['sit_through', 0.05], ['sleep', 0.04], ['slightly', 0.04], ['slow', 0.03], ['son', 0.03], ['sort', 0.03], ['spectacular', 0.04], ['stark', 0.06], ['steal', 0.03], ['steven', 0.1], ['strip', 0.05], ['supply', 0.05], ['sure', 0.02], ['survivor', 0.05], ['suspense', 0.04], ['take', 0.04], ['tension', 0.08], ['theatrical', 0.05], ['thing', 0.01], ['thriller', 0.03], ['toy', 0.04], ['trap', 0.04], ['try', 0.02], ['tv', 0.02], ['unsympathetic', 0.06], ['valuable', 0.11], ['version', 0.05], ['video', 0.03], ['water', 0.04], ['wilson', 0.05], ['worker', 0.05], ['worried', 0.06]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2G9R7dPxW9jY"
      },
      "source": [
        "**Setting up data for scikit learn**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "y1PuYBBELkb9",
        "colab": {}
      },
      "source": [
        "# for scikit learn we need to transform the sparce tuples to a numpy array\n",
        "X_train = np.vstack([sparse2full(doc, len(id2word)) for doc in tfidf[train_corpus]])\n",
        "X_test = np.vstack([sparse2full(doc, len(id2word)) for doc in tfidf[test_corpus]])\n",
        "\n",
        "# getting labels from pd\n",
        "y_train = train_set.target\n",
        "y_test = test_set.target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BVtnko8--O7O",
        "colab": {}
      },
      "source": [
        "# safe preprocessed data\n",
        "np.save(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/X_train2.npy\", X_train)\n",
        "np.save(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/X_test2.npy\", X_test)\n",
        "np.save(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/y_train2.npy\", y_train)\n",
        "np.save(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/y_test2.npy\", y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "myuqJxwp_FYZ",
        "colab": {}
      },
      "source": [
        "X_train = np.load(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/X_train2.npy\")\n",
        "X_test = np.load(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/X_test2.npy\")\n",
        "y_train = np.load(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/y_train2.npy\")\n",
        "y_test = np.load(\"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/y_test2.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G7K00iBeI522"
      },
      "source": [
        "## 1.2 Modelling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3HOg7y-_Zd7i"
      },
      "source": [
        "**Random forrest**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "AAxCe2RtZfHs",
        "outputId": "27ff9f00-9de3-480c-dd02-a23cddabf983",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "# Setting up grid search for a random forest\n",
        "rf_params = {\n",
        "    'bootstrap': [True],\n",
        "    'max_depth': [5, 10, 30, 50],\n",
        "    'max_features': [2, 3],\n",
        "    'min_samples_leaf': [3, 5],\n",
        "    'min_samples_split': [8, 12],\n",
        "    'n_estimators': [100, 300, 1000]\n",
        "}\n",
        "# Create a model\n",
        "rf = RandomForestClassifier(n_jobs=2)\n",
        "# Instantiate the grid search model\n",
        "rf_gs = GridSearchCV(estimator=rf, param_grid=rf_params, cv=3)\n",
        "rf_gs = rf_gs.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 13min 5s, sys: 45.1 s, total: 13min 50s\n",
            "Wall time: 52min 55s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lnz3P4cIaddc",
        "outputId": "5ed63b1b-1a41-46c8-b790-e6ef7afb8849",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# get best score from grid search\n",
        "print('RF best CV accuracy: ' + str(round(rf_gs.best_score_, 3)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF best CV accuracy: 0.844\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1c1drauTagx8",
        "outputId": "bc93f3db-65c3-4002-93cc-f0aebf010d83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# train model with best params from grid search\n",
        "rf = rf_gs.best_estimator_\n",
        "rf.fit(X_train, y_train)\n",
        "y_pred = rf.predict(X_test)\n",
        "rf_acc = str(round(accuracy_score(y_test, y_pred), 3))\n",
        "print('RF accuracy on test set: ' + rf_acc)\n",
        "\n",
        "# safe model\n",
        "joblib.dump(rf, \n",
        "            \"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/rf2.sav\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RF accuracy on test set: 0.848\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Coding/NLP_project/preprocessed_data/rf2.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZQDsKdQ-lTpb"
      },
      "source": [
        "**Elastic net**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lDAV0WCOPI35",
        "outputId": "64bcb0e8-86ee-41ed-bc7e-70a3fa9ff4bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%%time\n",
        "# Setting up grid search for an elastic net\n",
        "net_params = {\"alpha\": np.arange(0.1, 0.5, 0.05),\n",
        "              \"l1_ratio\": np.arange(0.0, 0.5, 0.1)}\n",
        "# Create a model\n",
        "net = linear_model.SGDClassifier(n_jobs=-1, loss='log', penalty='elasticnet')\n",
        "# Instantiate the grid search model\n",
        "net_classifier_gs = GridSearchCV(net, net_params, cv=3)\n",
        "net_classifier_gs = net_classifier_gs.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 6min 48s, sys: 14.2 s, total: 7min 2s\n",
            "Wall time: 6min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8xnQLUoXk5_y",
        "outputId": "05b40304-988b-4ee8-ff75-d04ddda79439",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# get best score from grid search\n",
        "print('Elastic net best CV accuracy: ' + str(net_classifier_gs.best_score_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elastic net best CV accuracy: 0.83004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vs2TEtLshdUL",
        "outputId": "3434af97-80e7-4239-e229-eb18bbb02648",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# train model with best params from grid search\n",
        "best_net_classifier = net_classifier_gs.best_estimator_\n",
        "best_net_classifier.fit(X_train, y_train)\n",
        "y_pred = best_net_classifier.predict(X_test)\n",
        "el_acc = str(round(accuracy_score(y_test, y_pred),3))\n",
        "print('Elastic net best accuracy on test set: ' + el_acc)\n",
        "\n",
        "# safe model\n",
        "joblib.dump(best_net_classifier,\n",
        "            \"/content/drive/My Drive/Coding/NLP_project/preprocessed_data/best_net_classifier2.sav\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elastic net best accuracy on test set: 0.837\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/drive/My Drive/Coding/NLP_project/preprocessed_data/best_net_classifier2.sav']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "S6g5tqPXlXxE",
        "colab": {}
      },
      "source": [
        "coefficients = best_net_classifier.coef_\n",
        "index = coefficients.argsort()\n",
        "smallest_50 = index[0,0:50].tolist()\n",
        "highest_50 = index[0,-50::1].tolist()\n",
        "# Look up feature names\n",
        "smallest_50_words = [id2word[ind] for ind in smallest_50]\n",
        "highest_50_words = [id2word[ind] for ind in highest_50]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yUYZ2ugyFI8Q"
      },
      "source": [
        "## 1.3 Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tfwuTtCej9TX",
        "outputId": "bf685a18-0a8e-45c8-d6ae-066cd3393dce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "# Summary\n",
        "print('Elastic net best CV accuracy: ' + str(round(net_classifier_gs.best_score_,3)))\n",
        "print('Elastic net best accuracy on test set: ' + el_acc)\n",
        "print('Random forest best CV accuracy: ' + str(round(rf_gs.best_score_, 3)))\n",
        "print('Random forest accuracy on test set: ' + rf_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Elastic net best CV accuracy: 0.83\n",
            "Elastic net best accuracy on test set: 0.837\n",
            "Random forest best CV accuracy: 0.844\n",
            "Random forest accuracy on test set: 0.848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "JQQ7eeUvKS3y"
      },
      "source": [
        "By the rather simple approach of creating TFIDFs and using these as features for a 'classical' classifier, we received an accuracy of 85% on the test set with a random forest. This is a decent baseline for benchmarking more complicated models.\n",
        "\n",
        "In the following, the 10 features with the smallest and the 10 features with the highest coefficients (of the elastic net) are printed out. These are the features which impact the models decision the most. \n",
        "\n",
        "Unsurprisingly, the words that drive towards classifiying the review as positive are mostly single words that one would itself connect to a positive sentiment and the other way around. \n",
        "\n",
        "(Interestingly, the word \"war\" drives the model towards a positive prediction. This could be an overfitting towards the IMDb corpus. Maybe war movies are judged more positive by the viewers in general.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBFzolsE0NiC",
        "outputId": "8ddbda2d-83ac-4aeb-c615-cbafb89b65fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print('Words indicating a negative sentiment:')\n",
        "print(smallest_50_words[:10])\n",
        "print('Words indicating a positive sentiment:')\n",
        "print(highest_50_words[:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Words indicating a negative sentiment:\n",
            "['bad', 'waste', 'awful', 'terrible', 'stupid', 'horrible', 'plot', 'poor', 'money', 'minute']\n",
            "Words indicating a positive sentiment:\n",
            "['beautifully', 'powerful', 'incredible', 'perfectly', 'unique', 'outstanding', 'simple', 'war', 'live', 'season']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yXM7uwtdBsCR"
      },
      "source": [
        "The biggest problem of the model is that it only evaluates based on the impact of single words and does not regard the context. So, related words like \"not good\" or \"I do not like\" can be misinterpreted.\n",
        "\n",
        "Evaluating the review without context is often not sufficient -- for example, when one uses irony or talks positively about a movie with a very dark topic.\n",
        "\n",
        "To illustrate this, let us look at the following review. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tduhjTdbG8du",
        "outputId": "36b2c17b-4aa4-4184-9634-b9e09633df30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "#load the model\n",
        "path = '/content/drive/My Drive/Coding/NLP_project/preprocessed_data/'\n",
        "model = joblib.load(path + 'best_net_classifier2.sav')\n",
        "doc = 19\n",
        "pp = pprint.PrettyPrinter()\n",
        "pp.pprint(test_set.data[doc].decode('utf-8'))\n",
        "print('\\n predicted label: ' + str(model.predict(X_test[doc,:].reshape(1, -1)))[1])\n",
        "print('\\n true label: ' + str(y_test[doc]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('New York family is the last in their neighborhood to get a television set, '\n",
            " \"which nearly ruins David Niven's marriage to Mitzi Gaynor. Bedroom comedy \"\n",
            " 'that rarely ventures into the bedroom(and nothing sexy happens there '\n",
            " 'anyway). Gaynor as an actress has about as much range as an oven--she turns '\n",
            " \"on, she turns off. Film's sole compensation is a supporting performance by \"\n",
            " 'perky Patty Duke, pre-\"Miracle Worker\", as Niven\\'s daughter. She\\'s '\n",
            " 'delightful; \"Happy Anniversary\" is not. * from ****')\n",
            "\n",
            " predicted label: 1\n",
            "\n",
            " true label: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CZOs7NglKxhb"
      },
      "source": [
        "This document is correctly labeled as negative (0). For humans, the sentence \"Gaynor as an actress has about as much range as an oven--she turns on, she turns off.\" is clearly meant negative. However, each word by itself has no negative connotation. The context is what makes us understand the real sentiment. The words \"delightful\" and \"Happy\" have a positive connotation and are more frequent in positive sentiments, leading the model to falsely predict the review as positive (1).\n",
        "\n",
        "To conclude, we need context to further increase the accuracy. Therefore, we need to use another model such as an LSTM that can handle sentences. And, of course, we need to preprocess the data differently. We need sequences instead of BoW.\n",
        "\n",
        "(Surely, we could try to improve the accuracy with the TFIDF approach by playing around with the preprocessing. Another trick is to create bigrams and trigrams that contain at least some local context. In fact we did this during preprocessing, but we also set a threshhold and did only keep very few of the bi- and trigrams. We could play around more with the threshhold. We could think more about which words to filter out and which not to filter out according to their POS tag. We could use different statistical models on top and try to further tune them.)\n"
      ]
    }
  ]
}